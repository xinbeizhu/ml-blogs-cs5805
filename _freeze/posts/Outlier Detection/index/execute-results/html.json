{
  "hash": "0be902e403607f188b7084fc62376645",
  "result": {
    "markdown": "---\ntitle: Anomaly/Outlier Detection\nauthor: Xinbei Zhu\ndate: 2023-12-1\ncategories:\n  - code\n  - analysis\nimage: detection.jpg\n---\n\nThis blog is about Anomaly/Outlier Detection. Anomaly/Outlier detection, in simple terms, is like finding the odd ones out in a group. Imagine we have a basket of apples, and most of them are red, but a few are green. In this case, the green apples are the outliers because they're different from the majority, which are red.\n\nIn the world of data and statistics, outlier detection works in a similar way. It's the process of identifying data points that are significantly different or unusual compared to the rest of the data. Think of it as spotting something that doesn't quite fit in with the rest.\n\nAnomaly or outlier detection in machine learning is a process aimed at identifying data points, events, or observations that deviate significantly from the majority of the data. These anomalies can indicate critical incidents, such as bank fraud, structural defects, medical problems, or errors in text. Anomaly detection is widely used in various fields like finance, healthcare, fault detection, system health monitoring, event detection in sensor networks, and eco-informatics.\n\nOutlier detection is important because these unusual data points can sometimes indicate a problem or an error, like a mistake in measurement, or they could be a sign of something interesting and worth exploring further, like a new trend.\n\nThere are three types of anomalies:\n\n-   **Point Anomalies**: A single instance of data is anomalous if it's too far off from the rest. This is the simplest type of anomaly and is common in fraud detection.\n-   **Contextual Anomalies**: Anomalies that depend on the context of a situation. This is common in time-series data where a data point might be anomalous in a certain context but not otherwise.\n-   **Collective Anomalies**: A collection of data points is anomalous with respect to the entire dataset. This is common in intrusion detection or ecosystem disturbances.\n\n### Task Demo\n\nIn this task, I utilize the anomaly/outlier detection technology to detect the fraud in credit card. I adopt the **Credit Card Fraud Detection** from Kaggle. I use supervised learning to train a outlier detection model and detect the anomaly.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import SMOTE\n```\n:::\n\n\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Load the dataset\ndf = pd.read_csv('dataset/creditcard.csv')\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Data preprocessing\n# Truncate the dataset, use the first 50,000 rows\ndf_truncated = df.head(50000)\ndf = df_truncated\nX = df.drop('Class', axis=1)\ny = df['Class']\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Feature scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Dimensionality Reduction for Visualization\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Apply DBSCAN\ndbscan = DBSCAN(eps=0.3, min_samples=10)\nclusters = dbscan.fit_predict(X_pca)\n```\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Scatter Plot before Model Prediction\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='Paired', marker='o')\nplt.title('DBSCAN Clustering')\nplt.xlabel('PCA Feature 1')\nplt.ylabel('PCA Feature 2')\nplt.colorbar(label='Cluster Label')\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<matplotlib.colorbar.Colorbar at 0x1b04bdb5810>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-2.png){width=481 height=523}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Splitting the dataset into the Training set and Test set\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n\n# Handling imbalanced data\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Training the Random Forest model\nclassifier = RandomForestClassifier(n_estimators=100, random_state=0)\nclassifier.fit(X_train_res, y_train_res)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Evaluating the model\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\n# Plotting the confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.matshow(cm, cmap=plt.cm.gray)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix:\n[[9965    2]\n [   7   26]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      9967\n           1       0.93      0.79      0.85        33\n\n    accuracy                           1.00     10000\n   macro avg       0.96      0.89      0.93     10000\nweighted avg       1.00      1.00      1.00     10000\n\nAccuracy Score: 0.9991\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-2.png){width=409 height=418}\n:::\n:::\n\n\nThe results show that the model performs well. The confusion matrix indicates a low number of false positives and false negatives, and the model also exhibits a high accuracy rate.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}